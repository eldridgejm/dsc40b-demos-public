{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Using Minimum Spanning Trees\n",
    "\n",
    "### By Daniel Lee, Udaikaran Singh, and Justin Eldridge\n",
    "\n",
    "In this notebook, we will show how minimum spanning trees can be used to cluster data. Along the way, we will implement Kruskal's Algorithm for computing MSTs.\n",
    "\n",
    "We will start by importing some familiar packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import random\n",
    "import math\n",
    "\n",
    "# make plots bigger by default\n",
    "plt.rcParams['figure.figsize'] = (8,8)\n",
    "plt.rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the course's own simple dict-of-sets data structure to represent graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsc40graph import UndirectedGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geyser Eruptions\n",
    "\n",
    "The file `faithful.csv` contains data on 269 eruptions of the Old Faithful geyser in Yellowstone National Park. A scatter plot of the data is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geyser = np.loadtxt('faithful.csv', skiprows=1, delimiter=',')\n",
    "plt.scatter(*geyser.T)\n",
    "\n",
    "plt.xlabel('Duration')\n",
    "plt.ylabel('Wait')\n",
    "plt.title('Eruptions of Old Faithful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the geyser appears to erupt in two \"modes\": either with high frequency and short duration, or low frequency and long duration. We wish to \"cluster\" the above data in order to recover these two modes automatically. Our strategy will be as follows:\n",
    "\n",
    "1. Construct the distance graph of the data. This is a weighted graph in which every node is a data point, and the weight of each edge is the distance between its endpoints.\n",
    "2. Compute the MST of the distance graph.\n",
    "3. Remove the longest edge in the MST. This creates two connected components; these are the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kruskal's Algorithm\n",
    "\n",
    "In lecture, we saw that Kruskal's Algorithm can be used to compute minimum spanning trees. We will now implement this algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kruskal(graph, weight):\n",
    "    \"\"\"Compute the MST of the graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : UndirectedGraph\n",
    "        The graph whose MST will be computed.\n",
    "    weight : callable\n",
    "        A function which returns the weight of an edge.\n",
    "        \n",
    "    \"\"\"\n",
    "    mst = UndirectedGraph()\n",
    "    forest = DisjointSet()\n",
    "    \n",
    "    # sort edges from lightest to heaviest\n",
    "    weighted_edges = sorted(graph.edges, key=weight)\n",
    "    \n",
    "    # intialize disjoint-set forest\n",
    "    for node in graph.nodes:\n",
    "        forest.make_set(node)\n",
    "    \n",
    "    for (u, v) in weighted_edges:\n",
    "        if forest.find(u) != forest.find(v):\n",
    "            forest.union(u, v)\n",
    "            mst.add_edge(u, v)\n",
    "    \n",
    "    return mst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kruskal's Algorithm makes use of a \"disjoint set forest\" data structure which provides a way to efficiently union disjoint sets and to determine if two points belong to the same set. In the context of Kruskal's algorithm, we use a disjoint set to quickly determine whether any two vertices have been connected yet or not.\n",
    "\n",
    "We implement a disjoint set forest in the `DisjointSet` class below. For more information, see \"Introduction to Algorithms\", 3rd edition, by Cormen, Leiserson, Rivest, and Stein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisjointSet:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.parent = dict()\n",
    "        self.rank = dict()\n",
    "        \n",
    "    def make_set(self, vertex):\n",
    "        \"\"\"Create a new singleton set.\"\"\"\n",
    "        self.parent[vertex] = vertex\n",
    "        self.rank[vertex] = 0\n",
    "\n",
    "    def find(self, vertex):\n",
    "        \"\"\"Find the ID of the set to which the vertex belongs.\"\"\"\n",
    "        if self.parent[vertex] != vertex:\n",
    "            self.parent[vertex] = self.find(self.parent[vertex])\n",
    "        return self.parent[vertex]\n",
    "\n",
    "    def union(self, v1, v2):\n",
    "        \"\"\"Union the set containing v1 with the set containiing v2.\"\"\"\n",
    "        root1 = self.find(v1)\n",
    "        root2 = self.find(v2)\n",
    "        if root1 != root2:\n",
    "            if self.rank[root1] > self.rank[root2]:\n",
    "                self.parent[root2] = root1\n",
    "            else:\n",
    "                self.parent[root1] = root2\n",
    "        if self.rank[root1] == self.rank[root2]: \n",
    "            self.rank[root2] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test our implementation on the simple weighted graph below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./simple_weighted_graph.png\" width=30%>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the graph to code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = UndirectedGraph()\n",
    "graph.add_edge('a', 'b')\n",
    "graph.add_edge('b', 'c')\n",
    "graph.add_edge('c', 'd')\n",
    "graph.add_edge('a', 'd')\n",
    "graph.add_edge('a', 'c')\n",
    "\n",
    "def weight(edge):\n",
    "    u, v = edge\n",
    "    weights = {\n",
    "        ('a', 'b'): 2,\n",
    "        ('a', 'd'): 8,\n",
    "        ('d', 'c'): 3,\n",
    "        ('c', 'b'): 5,\n",
    "        ('a', 'c'): 1\n",
    "    }\n",
    "    try:\n",
    "        return weights[(u, v)]\n",
    "    except KeyError:\n",
    "        return weights[(v, u)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mst = kruskal(graph, weight)\n",
    "mst.edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edges of the MST are bolded in the graph below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./simple_weighted_mst.png\" width=30%>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MST of the Geyser Data\n",
    "\n",
    "Recall that our approach to clustering will involve computing the MST of the distance graph constructed from the data. We now create a simple helper function which takes in an array of data points and returns an `UndirectedGraph` along with the weight function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def distance_graph(data):\n",
    "    \"\"\"Given an n x d array of data, produces the distance graph on n nodes.\"\"\"\n",
    "    graph = UndirectedGraph()\n",
    "    n = len(data)\n",
    "    weight = {}\n",
    "    \n",
    "    for i, j in combinations(range(n), 2):\n",
    "        graph.add_edge(i, j)\n",
    "        weight[(i, j)] = np.linalg.norm(data[i] - data[j])\n",
    "        \n",
    "    def weight_function(edge):\n",
    "        u, v = edge\n",
    "        if (u, v) in weight:\n",
    "            return weight[(u,v)]\n",
    "        else:\n",
    "            return weight[(v,u)]\n",
    "            \n",
    "    return graph, weight_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we have everything we need to compute the MST of the distance graph constructed from the geyser data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, weight = distance_graph(geyser)\n",
    "mst = kruskal(graph, weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the graph is a distance graph computed from points in the plane, we can draw the MST by positioning each node at the coordinates of its corresponding data point. The result is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mst_edge(points, u, v, **kwargs):\n",
    "    points = np.vstack((points[u], points[v]))\n",
    "    plt.plot(points[:,0], points[:,1], **kwargs)\n",
    "\n",
    "plt.scatter(*geyser.T)\n",
    "for u, v in mst.edges:\n",
    "    plot_mst_edge(geyser, u, v, color='black', alpha=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this what you expected?\n",
    "\n",
    "Let's dig a little further. What is the biggest edge in the MST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_edge = max(mst.edges, key=weight)\n",
    "biggest_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below plot highlights the biggest edge in red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*geyser.T)\n",
    "for u, v in mst.edges:\n",
    "    plot_mst_edge(geyser, u, v, color='black', alpha=.5)\n",
    "plot_mst_edge(geyser, *biggest_edge, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may not look like this is the biggest edge, but look again. Is there a bug in our code?\n",
    "\n",
    "There is not. This is an issue of scale: the values on the $y$-axis are much different from the values on the $x$-axis, and so what looks like a small gap between points is actually a gigantic leap. This becomes clearer if we force the axes of the plot to be drawn at the same scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.scatter(*geyser.T)\n",
    "for u, v in mst.edges:\n",
    "    plot_mst_edge(geyser, u, v, color='black', alpha=.5)\n",
    "plot_mst_edge(geyser, *biggest_edge, color='red')\n",
    "\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, changing how the data is plotted does not affect the MST. We need to scale the data itself in order to get the tree we were expected. A natural way to do this is to *standardize* (i.e., $z$-score) the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    return (x - np.mean(x, axis=0)) / np.std(x, axis=0)\n",
    "\n",
    "scaled_geyser = np.empty_like(geyser)\n",
    "scaled_geyser = standardize(geyser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standardized data looks the same. But check out the axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*scaled_geyser.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute the MST of the scaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, scaled_weight = distance_graph(scaled_geyser)\n",
    "scaled_mst = kruskal(graph, scaled_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*scaled_geyser.T)\n",
    "for u, v in scaled_mst.edges:\n",
    "    points = np.vstack((scaled_geyser[u], scaled_geyser[v]))\n",
    "    plt.plot(points[:,0], points[:,1], color='black', alpha=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering the Geyser MST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that our strategy for clustering has us deleting the longest edge of the MST and finding the resulting connected components -- these are our clusters. To find the connected components, we can use BFS or DFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def bfs_component(graph, source, status=None):\n",
    "    \"\"\"Start a BFS at `source`.\"\"\"\n",
    "    if status is None:\n",
    "        status = {node: 'undiscovered' for node in graph.nodes}\n",
    "\n",
    "    status[source] = 'pending'\n",
    "    pending = deque([source])\n",
    "    component = set()\n",
    "\n",
    "    # while there are still pending nodes\n",
    "    while pending: \n",
    "        u = pending.popleft() # pop from left (front of queue)\n",
    "        component.add(u)\n",
    "        \n",
    "        for v in graph.neighbors(u, sort=True):\n",
    "            # explore edge (u,v)\n",
    "            if status[v] == 'undiscovered':\n",
    "                status[v] = 'pending'\n",
    "                pending.append(v) # append to right (back of queue)\n",
    "        status[u] = 'visited'\n",
    "        \n",
    "    return component\n",
    "        \n",
    "def connected_components(graph):\n",
    "    status = {node: 'undiscovered' for node in graph.nodes}\n",
    "    \n",
    "    components = []\n",
    "    for node in graph.nodes:\n",
    "        if status[node] == 'undiscovered':\n",
    "            component = bfs_component(graph, node, status=status)\n",
    "            components.append(component)\n",
    "            \n",
    "    return components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out. The MST is shown with the largest edge removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_edge = max(scaled_mst.edges, key=scaled_weight)\n",
    "scaled_mst.remove_edge(*biggest_edge)\n",
    "\n",
    "plt.scatter(*scaled_geyser.T)\n",
    "for u, v in scaled_mst.edges:\n",
    "    points = np.vstack((scaled_geyser[u], scaled_geyser[v]))\n",
    "    plt.plot(points[:,0], points[:,1], color='black', alpha=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then find the connected components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = connected_components(scaled_mst)\n",
    "\n",
    "def points_by_component(data, components):\n",
    "    for component in components:\n",
    "        yield data[list(component)]\n",
    "        \n",
    "for points in points_by_component(scaled_geyser, components):\n",
    "    plt.scatter(*points.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully separated the data into two reasonable-looking clusters. We can generalize this process so that it produces more than two clusters by deleting more edges from the MST. The resulting algorithm is often called *single-linkage clustering*. We encapsulate it in a function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_linkage_clustering(data, n_clusters=2):\n",
    "    graph, weight = distance_graph(data)\n",
    "    mst = kruskal(graph, weight)\n",
    "    for i in range(n_clusters-1):\n",
    "        biggest_edge = max(mst.edges, key=weight)\n",
    "        mst.remove_edge(*biggest_edge)\n",
    "    components = connected_components(mst)\n",
    "    return components, mst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, mst = single_linkage_clustering(scaled_geyser, n_clusters=2)\n",
    "\n",
    "for points in points_by_component(scaled_geyser, clusters):\n",
    "    plt.scatter(*points.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Examples on Synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load a different data set, remembering to standardize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_and_sparse = standardize(np.loadtxt('sample_dataset_2.txt'))\n",
    "dense_and_sparse = dense_and_sparse[np.random.choice(len(dense_and_sparse), 500)]\n",
    "plt.scatter(*dense_and_sparse.T)\n",
    "\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many clusters do you see in the data?\n",
    "\n",
    "Play with this parameter by changing the k value in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, mst = single_linkage_clustering(dense_and_sparse, n_clusters=5)\n",
    "\n",
    "for points in points_by_component(dense_and_sparse, clusters):\n",
    "    plt.scatter(*points.T)\n",
    "    \n",
    "for (u,v) in mst.edges:\n",
    "    plot_mst_edge(dense_and_sparse, u, v, color='black')\n",
    "    \n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try SLC on a noisier data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noisy = standardize(np.loadtxt('sample_dataset_1.txt'))\n",
    "noisy = noisy[np.random.choice(len(noisy), 500)]\n",
    "plt.scatter(*noisy.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many clusters do you see in the data?\n",
    "\n",
    "Play with this parameter by changing the k value in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, mst = single_linkage_clustering(noisy, n_clusters=15)\n",
    "\n",
    "for points in points_by_component(noisy, clusters):\n",
    "    plt.scatter(*points.T)\n",
    "    \n",
    "for (u,v) in mst.edges:\n",
    "    plot_mst_edge(noisy, u, v, color='black')\n",
    "    \n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise is making clustering difficult. One way to make things better is to remove outliers. An outlier is a point which does not have many points around it. We can quantify this by calculating the distance from each point to its $k$th closest neighbor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_kth_neighbor(data, k):\n",
    "    distances = distance_matrix(data, data)\n",
    "    return np.partition(distances, k, axis=1)[:,k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_k = distance_to_kth_neighbor(noisy, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the distance from each point to its 5th closest neighbor by coloring the point. This distance is small for dark points, and large for light points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*noisy.T, c=r_k)\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A histogram of the distances to the $k$th neighbor shows a long tail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r_k, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reasonable approach is to throw out the top 10% of points by their distance to the $k$th neighbor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(r_k, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_noisy = noisy[r_k < .19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these points removed, the data looks cleaner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*less_noisy.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now clustering gives a much better result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, mst = single_linkage_clustering(less_noisy, n_clusters=15)\n",
    "\n",
    "for (u,v) in mst.edges:\n",
    "    plot_mst_edge(less_noisy, u, v, color='black', alpha=.5)\n",
    "\n",
    "for points in points_by_component(less_noisy, clusters):\n",
    "    plt.scatter(*points.T)\n",
    "    \n",
    "plt.gca().set_aspect('equal')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
